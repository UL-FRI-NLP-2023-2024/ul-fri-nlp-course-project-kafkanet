
@inproceedings{alaimi_pedagogical_2020,
	title = {Pedagogical Agents for Fostering Question-Asking Skills in Children},
	url = {http://arxiv.org/abs/2004.03472},
	doi = {10.1145/3313831.3376776},
	abstract = {Question asking is an important tool for constructing academic knowledge, and a self-reinforcing driver of curiosity. However, research has found that question asking is infrequent in the classroom and children's questions are often superficial, lacking deep reasoning. In this work, we developed a pedagogical agent that encourages children to ask divergent-thinking questions, a more complex form of questions that is associated with curiosity. We conducted a study with 95 fifth grade students, who interacted with an agent that encourages either convergent-thinking or divergent-thinking questions. Results showed that both interventions increased the number of divergent-thinking questions and the fluency of question asking, while they did not significantly alter children's perception of curiosity despite their high intrinsic motivation scores. In addition, children's curiosity trait has a mediating effect on question asking under the divergent-thinking agent, suggesting that question-asking interventions must be personalized to each student based on their tendency to be curious.},
	pages = {1--13},
	booktitle = {Proceedings of the 2020 {CHI} Conference on Human Factors in Computing Systems},
	author = {Alaimi, Mehdi and Law, Edith and Pantasdo, Kevin Daniel and Oudeyer, Pierre-Yves and Sauzeon, Helene},
	urldate = {2024-03-21},
	date = {2020-04-21},
	eprinttype = {arxiv},
	eprint = {2004.03472 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Human-Computer Interaction, J.0, J.4, K.3.0, K.3.1, K.4.2},
	file = {arXiv Fulltext PDF:C\:\\Users\\Luka\\Zotero\\storage\\6BMWBVK6\\Alaimi et al. - 2020 - Pedagogical Agents for Fostering Question-Asking S.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Luka\\Zotero\\storage\\7SY8P3XW\\2004.html:text/html},
}

@article{bogaerds-hazenberg_what_2022,
	title = {What textbooks offer and what teachers teach: an analysis of the Dutch reading comprehension curriculum},
	volume = {35},
	issn = {1573-0905},
	url = {https://doi.org/10.1007/s11145-021-10244-4},
	doi = {10.1007/s11145-021-10244-4},
	shorttitle = {What textbooks offer and what teachers teach},
	abstract = {In the Netherlands, the quality of the reading curriculum is currently under debate because of disappointing results on national and international assessments of students’ reading skills and motivation. In a mixed-method study, we analyzed the content of Dutch textbooks for reading comprehension instruction (i.e., the implemented curriculum) and teachers’ evaluation and use of these books (i.e., the enacted curriculum). A materials analysis of reading comprehension lessons (N = 80) in eight textbooks for grades 4 and 5 was complemented with semi-structured teacher interviews (N = 29) and lesson observations (N = 11), with a focus on the quality of reading strategy and text structure instruction in the curriculum. Main findings are (1) a lack of alignment between lesson goals, theory, and assignments, (2) a strong focus on practicing strategies, (3) limited declarative knowledge about strategies and text structure, (4) little opportunities for self-regulated strategy application. The teachers that were interviewed mention similar problems, but still hardly deviate from the textbook’s content and pedagogical guidelines. We make recommendations to improve the quality of the curriculum.},
	pages = {1497--1523},
	number = {7},
	journaltitle = {Reading and Writing},
	shortjournal = {Read Writ},
	author = {Bogaerds-Hazenberg, Suzanne T. M. and Evers-Vermeul, Jacqueline and van den Bergh, Huub},
	urldate = {2024-03-21},
	date = {2022-09-01},
	langid = {english},
	keywords = {Enacted curriculum, Materials analysis, Mixed methods, Reading comprehension instruction, Reading strategy, Text structure},
	file = {Full Text PDF:C\:\\Users\\Luka\\Zotero\\storage\\ZST8J42Q\\Bogaerds-Hazenberg et al. - 2022 - What textbooks offer and what teachers teach an a.pdf:application/pdf},
}

@article{nielen_digital_2018,
	title = {Digital Guidance for Susceptible Readers: Effects on Fifth Graders’ Reading Motivation and Incidental Vocabulary Learning},
	volume = {56},
	issn = {0735-6331},
	url = {https://doi.org/10.1177/0735633117708283},
	doi = {10.1177/0735633117708283},
	shorttitle = {Digital Guidance for Susceptible Readers},
	abstract = {In this digital era, a fundamental challenge is to design digital reading materials in such a way that they improve children’s reading skills. Since reading books is challenging for many fifth graders—particularly for those genetically susceptible to attention problems—the researchers hypothesized that guidance from a digital Pedagogical Agent ({PA}) could improve students’ reading motivation and incidental vocabulary learning. Using a sample of 147 fifth-grade students, the researchers carried out a randomized control trial with three groups of students reading: (a) hardcopy (print) books, (b) digital books, and (c) digital books with a {PA}. For students with a genetic predisposition to attention problems, carriers of the {DRD}4 seven-repeat allele, the {PA} supported their incidental vocabulary learning. For noncarriers, there were no effects of the digital reading materials or the {PA}.},
	pages = {48--73},
	number = {1},
	journaltitle = {Journal of Educational Computing Research},
	author = {Nielen, Thijs M. J. and Smith, Glenn G. and Sikkema-de Jong, Maria T. and Drobisz, Jack and van Horne, Bill and Bus, Adriana G.},
	urldate = {2024-03-21},
	date = {2018-03-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Inc},
	file = {SAGE PDF Full Text:C\:\\Users\\Luka\\Zotero\\storage\\ZBHITA5B\\Nielen et al. - 2018 - Digital Guidance for Susceptible Readers Effects .pdf:application/pdf},
}

@incollection{goldberg_alternative_2001,
	title = {An Alternative “Description of Personality”: The Big-Five Factor Structure},
	isbn = {978-0-203-82284-5},
	shorttitle = {An Alternative “Description of Personality”},
	abstract = {In the 45 years since Cattell used English trait terms to begin the formulation of his “description of personality,” a number of investigators have proposed an alternative structure based on 5 orthogonal factors. The generality of this 5-factor model is here demonstrated across unusually comprehensive sets of trait terms. In the first of 3 studies, 1,431 trait adjectives grouped into 75 clusters were analyzed; virtually identical structures emerged in 10 replications, each based on a different factor-analytic procedure. A 2nd study of 479 common terms grouped into 133 synonym clusters revealed the same structure in 2 samples of self-ratings and in 2 samples of peer ratings. None of the factors beyond the 5th generalized across the samples. In the 3rd study, analyses of 100 clusters derived from 339 trait terms suggest their potential utility as Big-Five markers in future studies.},
	booktitle = {Personality and Personality Disorders},
	publisher = {Routledge},
	author = {Goldberg, Lewis R.},
	date = {2001},
	note = {Num Pages: 14},
}

@article{murray_literacy_2021,
	title = {Literacy is inadequate: young children need literacies},
	volume = {29},
	issn = {0966-9760},
	url = {https://doi.org/10.1080/09669760.2021.1883816},
	doi = {10.1080/09669760.2021.1883816},
	shorttitle = {Literacy is inadequate},
	pages = {1--5},
	number = {1},
	journaltitle = {International Journal of Early Years Education},
	author = {Murray, Jane},
	urldate = {2024-03-21},
	date = {2021-01-02},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/09669760.2021.1883816},
	file = {Full Text PDF:C\:\\Users\\Luka\\Zotero\\storage\\LZ77ZRCX\\Murray - 2021 - Literacy is inadequate young children need litera.pdf:application/pdf},
}

@misc{neuman_data_2023,
	title = {Data Augmentation for Modeling Human Personality: The Dexter Machine},
	url = {http://arxiv.org/abs/2301.08606},
	doi = {10.48550/arXiv.2301.08606},
	shorttitle = {Data Augmentation for Modeling Human Personality},
	abstract = {Modeling human personality is important for several {AI} challenges, from the engineering of artificial psychotherapists to the design of persona bots. However, the field of computational personality analysis heavily relies on labeled data, which may be expensive, difficult or impossible to get. This problem is amplified when dealing with rare personality types or disorders (e.g., the anti-social psychopathic personality disorder). In this context, we developed a text-based data augmentation approach for human personality ({PEDANT}). {PEDANT} doesn't rely on the common type of labeled data but on the generative pre-trained model ({GPT}) combined with domain expertise. Testing the methodology on three different datasets, provides results that support the quality of the generated data.},
	number = {{arXiv}:2301.08606},
	publisher = {{arXiv}},
	author = {Neuman, Yair and Kozhukhov, Vladyslav and Vilenchik, Dan},
	urldate = {2024-03-21},
	date = {2023-01-20},
	eprinttype = {arxiv},
	eprint = {2301.08606 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\Luka\\Zotero\\storage\\HTN8K2WP\\Neuman et al. - 2023 - Data Augmentation for Modeling Human Personality .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Luka\\Zotero\\storage\\M7R8KP6R\\2301.html:text/html},
}

@thesis{papaioannou_designing_2022,
	title = {Designing coherent and engaging open-domain conversational {AI} systems},
	url = {https://www.ros.hw.ac.uk/handle/10399/4722},
	abstract = {Designing conversational {AI} systems able to engage in open-domain ‘social’ conversation is extremely challenging and a frontier of current research. Such systems are
required to have extensive awareness of the dialogue context and world knowledge,
the user intents and interests, requiring more complicated language understanding, dialogue management, and state and topic tracking mechanisms compared to
traditional task-oriented dialogue systems. Given the wide coverage of topics in
open-domain dialogue, the conversation can span multiple turns where a number of
complex linguistic phenomena (e.g. ellipsis and anaphora) are present and should
be resolved for the system to be contextually aware. Such systems also need to be
engaging, keeping the users’ interest over long conversations. These are only some
of the challenges that open-domain dialogue systems face. Therefore this thesis
focuses on designing dialogue systems able to hold extensive open-domain conversations in a coherent, engaging, and appropriate manner over multiple turns.
First, different types of dialogue systems architecture and design decisions
are discussed for social open-domain conversations, along with relevant evaluation
metrics. A modular architecture for ensemble-based conversational systems is
presented, called Alana, a finalist in the Amazon Alexa Prize Challenge in 2017 and
2018, able to tackle many of the challenges for open-domain social conversation.
The system combines different features such as topic tracking, contextual Natural
Language understanding, entity linking, user modelling, information retrieval, and
response ranking, using a rich representation of dialogue state.
The thesis next analyses the performance of the 2017 system and describes the
upgrades developed for the 2018 system. This leads to an analysis and comparison
of the real-user data collected in both years with different system configurations,
allowing assessment of the impact of different design decisions and modules.
Finally, Alana was integrated into an embodied robotic platform and enhanced
with the ability to also perform tasks. This system was deployed and evaluated
in a shopping mall in Finland. Further analysis of the added embodiment is presented and discussed, as well as the challenges of translating open-domain dialogue
systems into other languages. Data analysis of the collected real-user data shows
the importance of a variety of features developed and decisions made in the design
of the Alana system.},
	institution = {Heriot-Watt University},
	type = {Thesis},
	author = {Papaioannou, Ioannis},
	urldate = {2024-03-21},
	date = {2022-05},
	langid = {english},
	note = {Accepted: 2023-03-28T15:28:36Z},
	file = {Full Text PDF:C\:\\Users\\Luka\\Zotero\\storage\\T3S8ZJAT\\Papaioannou - 2022 - Designing coherent and engaging open-domain conver.pdf:application/pdf},
}

@article{zwaan_constructing_1998,
	title = {Constructing Multidimensional Situation Models During Reading},
	volume = {2},
	issn = {1088-8438},
	url = {https://doi.org/10.1207/s1532799xssr0203_2},
	doi = {10.1207/s1532799xssr0203_2},
	abstract = {We examined which dimensions of the situation model (time, space, causation, motivation, and protagonist) are monitored by readers during narrative comprehension. Clause or sentence reading times were collected in three experiments and analyzed using multiple-regression analyses. Experiment 1 showed that readers monitored temporal, causal, goal-related, and protagonist-related continuity because discontinuities on these dimensions led to reliable increases in reading times. This was not the case for spatial continuity. Prior to reading, participants in Experiment 2 memorized a map of the building in which the events described in the narratives took place. There was a reliable effect of the spatial dimension, as well as of the other dimensions. In Experiment 3, participants read the narratives of Experiment 2 but without having first memorized the map. There was no effect of the spatial dimension, but the effects were again reliable for the other dimensions. Reading times increased as a function of the number of situational continuity breaks. The results are discussed in the context of the event-indexing model (Zwaan, Langston, \& Graesser, 1995; Zwaan \& Radvansky, 1998).},
	pages = {199--220},
	number = {3},
	journaltitle = {Scientific Studies of Reading},
	author = {Zwaan, Rolf A. and Radvansky, Gabriel A. and Hilliard, Amy E. and Curiel, Jacqueline M.},
	urldate = {2024-03-21},
	date = {1998-07-01},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1207/s1532799xssr0203\_2},
}

@misc{wu_openicl_2023,
	title = {{OpenICL}: An Open-Source Framework for In-context Learning},
	url = {http://arxiv.org/abs/2303.02913},
	doi = {10.48550/arXiv.2303.02913},
	shorttitle = {{OpenICL}},
	abstract = {In recent years, In-context Learning ({ICL}) has gained increasing attention and emerged as the new paradigm for large language model ({LLM}) evaluation. Unlike traditional fine-tuning methods, {ICL} instead adapts the pre-trained models to unseen tasks without any parameter updates. However, the implementation of {ICL} is sophisticated due to the diverse retrieval and inference methods involved, as well as the varying pre-processing requirements for different models, datasets, and tasks. A unified and flexible framework for {ICL} is urgently needed to ease the implementation of the aforementioned components. To facilitate {ICL} research, we introduce {OpenICL}, an open-source toolkit for {ICL} and {LLM} evaluation. {OpenICL} is research-friendly with a highly flexible architecture that users can easily combine different components to suit their needs. It also provides various state-of-the-art retrieval and inference methods to streamline the process of adapting {ICL} to cutting-edge research. The effectiveness of {OpenICL} has been validated on a wide range of {NLP} tasks, including classification, {QA}, machine translation, and semantic parsing. As a side-product, we found {OpenICL} to be an efficient yet robust tool for {LLMs} evaluation. {OpenICL} is released at https://github.com/Shark-{NLP}/{OpenICL}},
	number = {{arXiv}:2303.02913},
	publisher = {{arXiv}},
	author = {Wu, Zhenyu and Wang, {YaoXiang} and Ye, Jiacheng and Feng, Jiangtao and Xu, Jingjing and Qiao, Yu and Wu, Zhiyong},
	urldate = {2024-03-21},
	date = {2023-03-06},
	eprinttype = {arxiv},
	eprint = {2303.02913 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\Luka\\Zotero\\storage\\XVM3Q4YR\\Wu et al. - 2023 - OpenICL An Open-Source Framework for In-context L.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Luka\\Zotero\\storage\\73IMDAYI\\2303.html:text/html},
}


@misc{cheng_compost_2023,
	title = {{CoMPosT}: Characterizing and Evaluating Caricature in {LLM} Simulations},
	url = {http://arxiv.org/abs/2310.11501},
	shorttitle = {{CoMPosT}},
	abstract = {Recent work has aimed to capture nuances of human behavior by using {LLMs} to simulate responses from particular demographics in settings like social science experiments and public opinion surveys. However, there are currently no established ways to discuss or evaluate the quality of such {LLM} simulations. Moreover, there is growing concern that these {LLM} simulations are flattened caricatures of the personas that they aim to simulate, failing to capture the multidimensionality of people and perpetuating stereotypes. To bridge these gaps, we present {CoMPosT}, a framework to characterize {LLM} simulations using four dimensions: Context, Model, Persona, and Topic. We use this framework to measure open-ended {LLM} simulations' susceptibility to caricature, defined via two criteria: individuation and exaggeration. We evaluate the level of caricature in scenarios from existing work on {LLM} simulations. We find that for {GPT}-4, simulations of certain demographics (political and marginalized groups) and topics (general, uncontroversial) are highly susceptible to caricature.},
	number = {{arXiv}:2310.11501},
	publisher = {{arXiv}},
	author = {Cheng, Myra and Piccardi, Tiziano and Yang, Diyi},
	urldate = {2024-03-21},
	date = {2023-10-17},
	eprinttype = {arxiv},
	eprint = {2310.11501 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
	file = {arXiv.org Snapshot:/Users/blaz/Zotero/storage/AHDYHBTZ/2310.html:text/html;Full Text PDF:/Users/blaz/Zotero/storage/D8WHCH4E/Cheng et al. - 2023 - CoMPosT Characterizing and Evaluating Caricature .pdf:application/pdf},
}

@misc{li_chatharuhi_2023,
	title = {{ChatHaruhi}: Reviving Anime Character in Reality via Large Language Model},
	url = {http://arxiv.org/abs/2308.09597},
	shorttitle = {{ChatHaruhi}},
	abstract = {Role-playing chatbots built on large language models have drawn interest, but better techniques are needed to enable mimicking specific fictional characters. We propose an algorithm that controls language models via an improved prompt and memories of the character extracted from scripts. We construct {ChatHaruhi}, a dataset covering 32 Chinese / English {TV} / anime characters with over 54k simulated dialogues. Both automatic and human evaluations show our approach improves role-playing ability over baselines. Code and data are available at https://github.com/{LC}1332/Chat-Haruhi-Suzumiya .},
	number = {{arXiv}:2308.09597},
	publisher = {{arXiv}},
	author = {Li, Cheng and Leng, Ziang and Yan, Chenxi and Shen, Junyi and Wang, Hao and {MI}, Weishi and Fei, Yaying and Feng, Xiaoyang and Yan, Song and Wang, {HaoSheng} and Zhan, Linkang and Jia, Yaokai and Wu, Pingyu and Sun, Haozhen},
	urldate = {2024-03-21},
	date = {2023-08-18},
	eprinttype = {arxiv},
	eprint = {2308.09597 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
	file = {arXiv.org Snapshot:/Users/blaz/Zotero/storage/65XT3LZ5/2308.html:text/html;Full Text PDF:/Users/blaz/Zotero/storage/UCVBM4BJ/Li et al. - 2023 - ChatHaruhi Reviving Anime Character in Reality vi.pdf:application/pdf},
}

@misc{chen_large_2023,
	title = {Large Language Models Meet Harry Potter: A Bilingual Dataset for Aligning Dialogue Agents with Characters},
	url = {http://arxiv.org/abs/2211.06869},
	shorttitle = {Large Language Models Meet Harry Potter},
	abstract = {In recent years, Dialogue-style Large Language Models ({LLMs}) such as {ChatGPT} and {GPT}4 have demonstrated immense potential in constructing open-domain dialogue agents. However, aligning these agents with specific characters or individuals remains a considerable challenge due to the complexities of character representation and the lack of comprehensive annotations. In this paper, we introduce the Harry Potter Dialogue ({HPD}) dataset, designed to advance the study of dialogue agents and character alignment. The dataset encompasses all dialogue sessions (in both English and Chinese) from the Harry Potter series and is annotated with vital background information, including dialogue scenes, speakers, character relationships, and attributes. These extensive annotations may empower {LLMs} to unlock character-driven dialogue capabilities. Furthermore, it can serve as a universal benchmark for evaluating how well can a {LLM} aligning with a specific character. We benchmark {LLMs} on {HPD} using both fine-tuning and in-context learning settings. Evaluation results reveal that although there is substantial room for improvement in generating high-quality, character-aligned responses, the proposed dataset is valuable in guiding models toward responses that better align with the character of Harry Potter.},
	number = {{arXiv}:2211.06869},
	publisher = {{arXiv}},
	author = {Chen, Nuo and Wang, Yan and Jiang, Haiyun and Cai, Deng and Li, Yuhan and Chen, Ziyang and Wang, Longyue and Li, Jia},
	urldate = {2024-03-21},
	date = {2023-10-09},
	eprinttype = {arxiv},
	eprint = {2211.06869 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/Users/blaz/Zotero/storage/6CWBMU8S/2211.html:text/html;Full Text PDF:/Users/blaz/Zotero/storage/ZME4RZF3/Chen et al. - 2023 - Large Language Models Meet Harry Potter A Bilingu.pdf:application/pdf},
}

@misc{shuster_am_2021,
	title = {Am I Me or You? State-of-the-Art Dialogue Models Cannot Maintain an Identity},
	url = {http://arxiv.org/abs/2112.05843},
	shorttitle = {Am I Me or You?},
	abstract = {State-of-the-art dialogue models still often stumble with regards to factual accuracy and self-contradiction. Anecdotally, they have been observed to fail to maintain character identity throughout discourse; and more specifically, may take on the role of their interlocutor. In this work we formalize and quantify this deficiency, and show experimentally through human evaluations that this is indeed a problem. In contrast, we show that discriminative models trained specifically to recognize who is speaking can perform well; and further, these can be used as automated metrics. Finally, we evaluate a wide variety of mitigation methods, including changes to model architecture, training protocol, and decoding strategy. Our best models reduce mistaken identity issues by nearly 65\% according to human annotators, while simultaneously improving engagingness. Despite these results, we find that maintaining character identity still remains a challenging problem.},
	number = {{arXiv}:2112.05843},
	publisher = {{arXiv}},
	author = {Shuster, Kurt and Urbanek, Jack and Szlam, Arthur and Weston, Jason},
	urldate = {2024-03-21},
	date = {2021-12-10},
	eprinttype = {arxiv},
	eprint = {2112.05843 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/Users/blaz/Zotero/storage/T85RLNPL/2112.html:text/html;Full Text PDF:/Users/blaz/Zotero/storage/J7AGGSYD/Shuster et al. - 2021 - Am I Me or You State-of-the-Art Dialogue Models C.pdf:application/pdf},
}

@inproceedings{ma_one_2021,
	title = {One Chatbot Per Person: Creating Personalized Chatbots based on Implicit User Profiles},
	url = {http://arxiv.org/abs/2108.09355},
	doi = {10.1145/3404835.3462828},
	shorttitle = {One Chatbot Per Person},
	abstract = {Personalized chatbots focus on endowing chatbots with a consistent personality to behave like real users, give more informative responses, and further act as personal assistants. Existing personalized approaches tried to incorporate several text descriptions as explicit user profiles. However, the acquisition of such explicit profiles is expensive and time-consuming, thus being impractical for large-scale real-world applications. Moreover, the restricted predefined profile neglects the language behavior of a real user and cannot be automatically updated together with the change of user interests. In this paper, we propose to learn implicit user profiles automatically from large-scale user dialogue history for building personalized chatbots. Specifically, leveraging the benefits of Transformer on language understanding, we train a personalized language model to construct a general user profile from the user's historical responses. To highlight the relevant historical responses to the input post, we further establish a key-value memory network of historical post-response pairs, and build a dynamic post-aware user profile. The dynamic profile mainly describes what and how the user has responded to similar posts in history. To explicitly utilize users' frequently used words, we design a personalized decoder to fuse two decoding strategies, including generating a word from the generic vocabulary and copying one word from the user's personalized vocabulary. Experiments on two real-world datasets show the significant improvement of our model compared with existing methods. Our code is available at https://github.com/zhengyima/{DHAP}},
	pages = {555--564},
	booktitle = {Proceedings of the 44th International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	author = {Ma, Zhengyi and Dou, Zhicheng and Zhu, Yutao and Zhong, Hanxun and Wen, Ji-Rong},
	urldate = {2024-03-21},
	date = {2021-07-11},
	eprinttype = {arxiv},
	eprint = {2108.09355 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/Users/blaz/Zotero/storage/BZXNVFNJ/2108.html:text/html;Full Text PDF:/Users/blaz/Zotero/storage/L8RA5D2Z/Ma et al. - 2021 - One Chatbot Per Person Creating Personalized Chat.pdf:application/pdf},
}

@misc{wang_easyedit_2024,
	title = {{EasyEdit}: An Easy-to-use Knowledge Editing Framework for Large Language Models},
	url = {http://arxiv.org/abs/2308.07269},
	shorttitle = {{EasyEdit}},
	abstract = {Large Language Models ({LLMs}) usually suffer from knowledge cutoff or fallacy issues, which means they are unaware of unseen events or generate text with incorrect facts owing to outdated/noisy data. To this end, many knowledge editing approaches for {LLMs} have emerged -- aiming to subtly inject/edit updated knowledge or adjust undesired behavior while minimizing the impact on unrelated inputs. Nevertheless, due to significant differences among various knowledge editing methods and the variations in task setups, there is no standard implementation framework available for the community, which hinders practitioners from applying knowledge editing to applications. To address these issues, we propose {EasyEdit}, an easy-to-use knowledge editing framework for {LLMs}. It supports various cutting-edge knowledge editing approaches and can be readily applied to many well-known {LLMs} such as T5, {GPT}-J, {LlaMA}, etc. Empirically, we report the knowledge editing results on {LlaMA}-2 with {EasyEdit}, demonstrating that knowledge editing surpasses traditional fine-tuning in terms of reliability and generalization. We have released the source code on {GitHub}, along with Google Colab tutorials and comprehensive documentation for beginners to get started. Besides, we present an online system for real-time knowledge editing, and a demo video.},
	number = {{arXiv}:2308.07269},
	publisher = {{arXiv}},
	author = {Wang, Peng and Zhang, Ningyu and Tian, Bozhong and Xi, Zekun and Yao, Yunzhi and Xu, Ziwen and Wang, Mengru and Mao, Shengyu and Wang, Xiaohan and Cheng, Siyuan and Liu, Kangwei and Ni, Yuansheng and Zheng, Guozhou and Chen, Huajun},
	urldate = {2024-03-21},
	date = {2024-03-19},
	eprinttype = {arxiv},
	eprint = {2308.07269 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Information Retrieval, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/blaz/Zotero/storage/LNU2RJQD/2308.html:text/html;Full Text PDF:/Users/blaz/Zotero/storage/HML2X4LK/Wang et al. - 2024 - EasyEdit An Easy-to-use Knowledge Editing Framewo.pdf:application/pdf},
}

@misc{wang_incharacter_2024,
	title = {{InCharacter}: Evaluating Personality Fidelity in Role-Playing Agents through Psychological Interviews},
	url = {http://arxiv.org/abs/2310.17976},
	shorttitle = {{InCharacter}},
	abstract = {Role-playing agents ({RPAs}), powered by large language models, have emerged as a flourishing field of applications. However, a key challenge lies in assessing whether {RPAs} accurately reproduce the personas of target characters, namely their character fidelity. Existing methods mainly focus on the knowledge and linguistic patterns of characters. This paper, instead, introduces a novel perspective to evaluate the personality fidelity of {RPAs} with psychological scales. Overcoming drawbacks of previous self-report assessments on {RPAs}, we propose {InCharacter}, namely Interviewing Character agents for personality tests. Experiments include various types of {RPAs} and {LLMs}, covering 32 distinct characters on 14 widely used psychological scales. The results validate the effectiveness of {InCharacter} in measuring {RPA} personalities. Then, with {InCharacter}, we show that state-of-the-art {RPAs} exhibit personalities highly aligned with the human-perceived personalities of the characters, achieving an accuracy up to 80.7\%. Our demo, code, dataset, and results are publicly available at https://github.com/Neph0s/{InCharacter}.},
	number = {{arXiv}:2310.17976},
	publisher = {{arXiv}},
	author = {Wang, Xintao and Xiao, Yunze and Huang, Jen-tse and Yuan, Siyu and Xu, Rui and Guo, Haoran and Tu, Quan and Fei, Yaying and Leng, Ziang and Wang, Wei and Chen, Jiangjie and Li, Cheng and Xiao, Yanghua},
	urldate = {2024-03-21},
	date = {2024-02-17},
	eprinttype = {arxiv},
	eprint = {2310.17976 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/Users/blaz/Zotero/storage/C2A7JQMP/2310.html:text/html;Full Text PDF:/Users/blaz/Zotero/storage/G7QNEKRV/Wang et al. - 2024 - InCharacter Evaluating Personality Fidelity in Ro.pdf:application/pdf},
}

@misc{wang_rolellm_2023,
	title = {{RoleLLM}: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models},
	url = {http://arxiv.org/abs/2310.00746},
	shorttitle = {{RoleLLM}},
	abstract = {The advent of Large Language Models ({LLMs}) has paved the way for complex tasks such as role-playing, which enhances user interactions by enabling models to imitate various characters. However, the closed-source nature of state-of-the-art {LLMs} and their general-purpose training limit role-playing optimization. In this paper, we introduce {RoleLLM}, a framework to benchmark, elicit, and enhance role-playing abilities in {LLMs}. {RoleLLM} comprises four stages: (1) Role Profile Construction for 100 roles; (2) Context-Based Instruction Generation (Context-Instruct) for role-specific knowledge extraction; (3) Role Prompting using {GPT} ({RoleGPT}) for speaking style imitation; and (4) Role-Conditioned Instruction Tuning ({RoCIT}) for fine-tuning open-source models along with role customization. By Context-Instruct and {RoleGPT}, we create {RoleBench}, the first systematic and fine-grained character-level benchmark dataset for role-playing with 168,093 samples. Moreover, {RoCIT} on {RoleBench} yields {RoleLLaMA} (English) and {RoleGLM} (Chinese), significantly enhancing role-playing abilities and even achieving comparable results with {RoleGPT} (using {GPT}-4).},
	number = {{arXiv}:2310.00746},
	publisher = {{arXiv}},
	author = {Wang, Zekun Moore and Peng, Zhongyuan and Que, Haoran and Liu, Jiaheng and Zhou, Wangchunshu and Wu, Yuhan and Guo, Hongcheng and Gan, Ruitong and Ni, Zehao and Zhang, Man and Zhang, Zhaoxiang and Ouyang, Wanli and Xu, Ke and Chen, Wenhu and Fu, Jie and Peng, Junran},
	urldate = {2024-03-21},
	date = {2023-10-01},
	eprinttype = {arxiv},
	eprint = {2310.00746 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/Users/blaz/Zotero/storage/UJMZNU8R/2310.html:text/html;Full Text PDF:/Users/blaz/Zotero/storage/UGZUE9HR/Wang et al. - 2023 - RoleLLM Benchmarking, Eliciting, and Enhancing Ro.pdf:application/pdf},
}

@misc{shao_character-llm_2023,
	title = {Character-{LLM}: A Trainable Agent for Role-Playing},
	url = {http://arxiv.org/abs/2310.10158},
	shorttitle = {Character-{LLM}},
	abstract = {Large language models ({LLMs}) can be used to serve as agents to simulate human behaviors, given the powerful ability to understand human instructions and provide high-quality generated texts. Such ability stimulates us to wonder whether {LLMs} can simulate a person in a higher form than simple human behaviors. Therefore, we aim to train an agent with the profile, experience, and emotional states of a specific person instead of using limited prompts to instruct {ChatGPT} {API}. In this work, we introduce Character-{LLM} that teach {LLMs} to act as specific people such as Beethoven, Queen Cleopatra, Julius Caesar, etc. Our method focuses on editing profiles as experiences of a certain character and training models to be personal simulacra with these experiences. To assess the effectiveness of our approach, we build a test playground that interviews trained agents and evaluates whether the agents {\textbackslash}textit\{memorize\} their characters and experiences. Experimental results show interesting observations that help build future simulacra of humankind.},
	number = {{arXiv}:2310.10158},
	publisher = {{arXiv}},
	author = {Shao, Yunfan and Li, Linyang and Dai, Junqi and Qiu, Xipeng},
	urldate = {2024-03-21},
	date = {2023-12-14},
	eprinttype = {arxiv},
	eprint = {2310.10158 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/Users/blaz/Zotero/storage/FHQLRIBT/2310.html:text/html;Full Text PDF:/Users/blaz/Zotero/storage/IC4DXJ5H/Shao et al. - 2023 - Character-LLM A Trainable Agent for Role-Playing.pdf:application/pdf},
}

@misc{shanahan_role-play_2023,
	title = {Role-Play with Large Language Models},
	url = {http://arxiv.org/abs/2305.16367},
	abstract = {As dialogue agents become increasingly human-like in their performance, it is imperative that we develop effective ways to describe their behaviour in high-level terms without falling into the trap of anthropomorphism. In this paper, we foreground the concept of role-play. Casting dialogue agent behaviour in terms of role-play allows us to draw on familiar folk psychological terms, without ascribing human characteristics to language models they in fact lack. Two important cases of dialogue agent behaviour are addressed this way, namely (apparent) deception and (apparent) self-awareness.},
	number = {{arXiv}:2305.16367},
	publisher = {{arXiv}},
	author = {Shanahan, Murray and {McDonell}, Kyle and Reynolds, Laria},
	urldate = {2024-03-21},
	date = {2023-05-25},
	eprinttype = {arxiv},
	eprint = {2305.16367 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/blaz/Zotero/storage/7Z635MYD/2305.html:text/html;Full Text PDF:/Users/blaz/Zotero/storage/HIPTEFKH/Shanahan et al. - 2023 - Role-Play with Large Language Models.pdf:application/pdf},
}

@software{Liu_LlamaIndex_2022,
author = {Liu, Jerry},
doi = {10.5281/zenodo.1234},
month = {11},
title = {{LlamaIndex}},
url = {https://github.com/jerryjliu/llama_index},
year = {2022}
}

@misc{llama,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{rag,
      title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks}, 
      author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
      year={2021},
      eprint={2005.11401},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{bge_embedding,
      title={C-Pack: Packaged Resources To Advance General Chinese Embedding}, 
      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff},
      year={2023},
      eprint={2309.07597},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
